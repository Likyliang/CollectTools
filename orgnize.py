# organize_from_exports.py
# ä½œç”¨ï¼šä» export_all.py äº§å‡ºçš„ tar åŒ…è§£å‹å¹¶â€œæŒ‰ä¼šè¯â€å½’æ¡£ï¼š
# - ä¼šè¯é”®ï¼šé‡‡é›†å·(ä¸‰ä½å­—æ¯/æ•°å­—) + åŠ¨ä½œ + æ—¥æœŸï¼ˆå¿½ç•¥ Left/Rightï¼‰
# - ä»£è¡¨æ—¶é—´ï¼šè¯¥ä¼šè¯å†…æœ€æ—©çš„ HHMMSSï¼Œç”¨äºä¼šè¯ç›®å½•æœ«å°¾
# - æ—¥å¿—è¯†åˆ«ï¼šlog_YYYYMMDD_HHMM_<CID>_<ACTION>_(FINAL|TEMP).txt
# - æœŸæœ›ï¼šæ¯ä¼šè¯ 7 ä¸ªæ–‡ä»¶ï¼ˆå« 1 ä¸ª log_*_FINAL/TEMPï¼‰
# - å®Œæˆåå¯¼å‡ºï¼šsession_summary_YYYYMMDD.csvã€session_anomalies_YYYYMMDD.txt

import datetime
import pathlib
import re
import tarfile
import tempfile
import shutil
import sys
from collections import defaultdict
import csv

# ====== å¯æ”¹é…ç½® ======
IMPORT_DIR   = pathlib.Path(r"D:\Data\Watch_Data_original")    # tar æ‰€åœ¨ç›®å½•
OUTPUT_ROOT  = pathlib.Path(r"D:\Data\Watch_Data_sessions")    # è¾“å‡ºæ ¹ç›®å½•
DATE         = None                                            # å¦‚ "20251026"ï¼ŒNone=äº¤äº’é€‰æ‹©/æˆ–ä¼ å‚
ALLOW_EXTS   = {".csv", ".jsonl", ".json", ".log", ".txt"}     # å‚ä¸å½’æ¡£çš„æ–‡ä»¶ç±»å‹
MAX_ASSIGN_DELTA_SEC = 600                                     # å…œåº•â€œå°±è¿‘åˆå¹¶â€çš„æœ€å¤§æ—¶é—´å·®ï¼ˆç§’ï¼‰
EXPECTED_FILES_PER_SESSION = 7                                 # æ¯ä¼šè¯åº”æœ‰çš„æ–‡ä»¶æ•°
# =====================

# ---------- æ—¥æœŸè§£æä¸äº¤äº’ ----------
DATE_PAT_ANY = re.compile(r"(\d{8})")

def _today():
    return datetime.datetime.now().strftime("%Y%m%d")

def _yesterday():
    return (datetime.datetime.now() - datetime.timedelta(days=1)).strftime("%Y%m%d")

def _list_available_dates(import_dir: pathlib.Path):
    if not import_dir.exists():
        return []
    dates = set()
    for tarf in import_dir.glob("*.tar"):
        m = DATE_PAT_ANY.search(tarf.name)
        if m:
            dates.add(m.group(1))
    return sorted(dates, reverse=True)

def _resolve_date(import_dir: pathlib.Path, preset: str | None) -> str:
    # å‘½ä»¤è¡Œå‚æ•°ä¼˜å…ˆ
    if len(sys.argv) > 1:
        cand = sys.argv[1].strip()
        if re.fullmatch(r"\d{8}", cand):
            return cand
        print(f"[ERROR] éæ³•æ—¥æœŸå‚æ•°: {cand}ï¼ˆåº”ä¸º yyyyMMddï¼‰")
        sys.exit(1)

    if preset and re.fullmatch(r"\d{8}", preset):
        return preset

    options = _list_available_dates(import_dir)
    today = _today()
    yest  = _yesterday()
    for d in (today, yest):
        if d not in options:
            options.append(d)
    options = sorted(set(options), reverse=True)

    if options:
        print("\nå¯ç”¨æ—¥æœŸï¼š")
        for i, d in enumerate(options, 1):
            print(f"  {i:2d}. {d}")
        print("  0 . æ‰‹åŠ¨è¾“å…¥ï¼ˆæˆ–ç›´æ¥å›è½¦=ä»Šå¤©ï¼‰")
        choice = input("è¯·é€‰æ‹©æ—¥æœŸç¼–å·ï¼š").strip()
        if choice == "":
            return today
        if choice == "0":
            while True:
                raw = input("è¯·è¾“å…¥æ—¥æœŸ (yyyyMMdd)ï¼Œå›è½¦=ä»Šå¤©ï¼Œy=æ˜¨å¤©ï¼Œq=é€€å‡ºï¼š").strip()
                if raw == "":
                    return today
                if raw.lower() in ("y", "yesterday"):
                    return yest
                if raw.lower() in ("q", "quit"):
                    print("å·²å–æ¶ˆã€‚"); sys.exit(0)
                if re.fullmatch(r"\d{8}", raw):
                    return raw
                print("æ ¼å¼ä¸å¯¹ï¼Œè¯·è¾“å…¥ 8 ä½æ—¥æœŸã€‚")
        try:
            idx = int(choice)
            if 1 <= idx <= len(options):
                return options[idx - 1]
        except Exception:
            pass
        print("[WARN ] è¾“å…¥æ— æ•ˆï¼Œä½¿ç”¨ä»Šå¤©ã€‚")
        return today
    else:
        while True:
            raw = input("æœªå‘ç°å¯ç”¨ tarã€‚è¯·è¾“å…¥æ—¥æœŸ (yyyyMMdd)ï¼Œå›è½¦=ä»Šå¤©ï¼Œy=æ˜¨å¤©ï¼Œq=é€€å‡ºï¼š").strip()
            if raw == "":
                return today
            if raw.lower() in ("y", "yesterday"):
                return yest
            if raw.lower() in ("q", "quit"):
                print("å·²å–æ¶ˆã€‚"); sys.exit(0)
            if re.fullmatch(r"\d{8}", raw):
                return raw
            print("æ ¼å¼ä¸å¯¹ï¼Œè¯·è¾“å…¥ 8 ä½æ—¥æœŸã€‚")

# ---------- æ–‡ä»¶åè§£æï¼ˆä¸¥æ ¼ï¼šCID=ä¸‰ä½å­—æ¯/æ•°å­—ï¼‰ ----------
# æ‰‹è¡¨/æ•°æ®æ–‡ä»¶ï¼š<CID>_<ACTION>_[Left|Right]_YYYYMMDD_(HHMMSS)
PAT_STRICT = re.compile(
    r"^(?P<cid>[0-9A-Za-z]{3})_(?P<action>.+?)_"
    r"(?:(?P<side>Left|Right)_)?"
    r"(?P<date>\d{8})"
    r"(?:_(?P<hms>\d{6}))?$",
    re.IGNORECASE
)

# å®½æ¾æœç´¢ï¼šæ–‡ä»¶åä»»æ„å¤„åŒ…å« <CID>_<ACTION>_[Left|Right]_YYYYMMDD_(HHMMSS)
PAT_RELAX_ANY = re.compile(
    r"(?P<cid>[0-9A-Za-z]{3})_(?P<action>.+?)_"
    r"(?:(?P<side>Left|Right)_)?"
    r"(?P<date>\d{8})"
    r"(?:_(?P<hms>\d{6}))?",
    re.IGNORECASE
)

# æ‰‹æœºå®Œæ•´æ—¥å¿—ï¼šlog_YYYYMMDD_HHMM_<CID>_<ACTION>_(FINAL|TEMP).txt
PAT_PHONE_TXT = re.compile(
    r"^log_(?P<date>\d{8})_(?P<hm>\d{4})_(?P<cid>[0-9A-Za-z]{3})_(?P<action>.+?)_(FINAL|TEMP)\.txt$",
    re.IGNORECASE
)

# ä»…æ—¥æœŸ+æ—¶é—´ï¼ˆç”¨äºå…œåº•ï¼‰ï¼šYYYYMMDD_HHMMSS æˆ– YYYYMMDD_HHMM
PAT_DATE_TIME_ONLY = re.compile(r"(?P<date>\d{8})_(?P<hms>\d{6}|\d{4})")

def parse_strict(name: str):
    m = PAT_STRICT.match(name)
    if not m:
        return None, None
    key = f"{m.group('cid')}_{m.group('action')}_{m.group('date')}"
    hms = m.group('hms')
    return key, hms

def parse_relax_any(name: str):
    m = PAT_RELAX_ANY.search(name)
    if not m:
        return None, None
    key = f"{m.group('cid')}_{m.group('action')}_{m.group('date')}"
    hms = m.group('hms')
    return key, hms

def parse_phone_txt(name: str):
    m = PAT_PHONE_TXT.match(name)
    if not m:
        return None, None
    date = m.group('date')
    hm   = m.group('hm')   # 4ä½
    cid  = m.group('cid')
    act  = m.group('action')
    key  = f"{cid}_{act}_{date}"
    hms  = hm + "00"       # HHMM -> HHMMSSï¼ˆè¡¥ 00 ç§’ï¼‰
    return key, hms

def parse_date_time_only(name: str):
    m = PAT_DATE_TIME_ONLY.search(name)
    if not m:
        return None, None
    date = m.group('date')
    hms  = m.group('hms')
    if len(hms) == 4:
        hms += "00"
    return date, hms

# ---------- å·¥å…· ----------
def hhmmss_to_sec(hms: str) -> int:
    return int(hms[0:2]) * 3600 + int(hms[2:4]) * 60 + int(hms[4:6])

def safe_move(src: pathlib.Path, dst: pathlib.Path):
    if not dst.exists():
        shutil.move(str(src), str(dst))
        return dst
    stem, suf = dst.stem, dst.suffix
    i = 1
    while True:
        cand = dst.with_name(f"{stem}_dup{i}{suf}")
        if not cand.exists():
            shutil.move(str(src), str(cand))
            return cand
        i += 1

def extract_tar(tar_path: pathlib.Path, to_dir: pathlib.Path):
    subdir = to_dir / tar_path.stem
    subdir.mkdir(parents=True, exist_ok=True)
    print(f"[WORK ] Extracting {tar_path.name} -> {subdir}")
    with tarfile.open(tar_path, "r:*") as tf:
        tf.extractall(path=subdir)
    return subdir

def collect_files(root: pathlib.Path, date_re: re.Pattern):
    files = []
    for p in root.rglob("*"):
        if p.is_file() and p.suffix.lower() in ALLOW_EXTS and date_re.search(p.name):
            files.append(p)
    return files

# ---------- æ±‡æ€»å¯¼å‡º ----------
def _iter_session_dirs(base_dir: pathlib.Path, date_str: str):
    for d in sorted(base_dir.iterdir()):
        if d.is_dir() and f"_{date_str}_" in d.name:
            yield d

def summarize_sessions(output_root: pathlib.Path, date_str: str, csv_path: pathlib.Path,
                       anomaly_path: pathlib.Path, expected_files_per_session: int):
    rows, anomalies = [], []
    for sess_dir in _iter_session_dirs(output_root, date_str):
        files = sorted([p for p in sess_dir.iterdir() if p.is_file()])
        count = len(files)
        name = sess_dir.name
        parts = name.split("_")
        collect_id = parts[0] if parts else ""
        action = "_".join(parts[1:-2]) if len(parts) >= 4 else ""
        rep_date = parts[-2] if len(parts) >= 2 else ""
        rep_time = parts[-1] if len(parts) >= 1 else ""
        rows.append({
            "session_dir": name,
            "collect_id": collect_id,
            "action": action,
            "date": rep_date,
            "time": rep_time,
            "file_count": count,
            "files": "; ".join([p.name for p in files]),
        })
        if count != expected_files_per_session:
            anomalies.append({
                "session_dir": name,
                "file_count": count,
                "files": [p.name for p in files],
            })

    print("\n===== Session Summary =====")
    for r in rows:
        mark = "" if r["file_count"] == expected_files_per_session else "  <-- ğŸš©å¼‚å¸¸"
        print(f"[SESSION] {r['session_dir']}  | æ•°é‡ = {r['file_count']}{mark}")

    csv_path.parent.mkdir(parents=True, exist_ok=True)
    with open(csv_path, "w", newline="", encoding="utf-8-sig") as f:
        writer = csv.DictWriter(f, fieldnames=["session_dir","collect_id","action","date","time","file_count","files"])
        writer.writeheader()
        writer.writerows(rows)
    print(f"[WRITE] æ±‡æ€»å·²ä¿å­˜ï¼š{csv_path}")

    if anomalies:
        with open(anomaly_path, "w", encoding="utf-8") as f:
            for a in anomalies:
                f.write(f"[ANOM] {a['session_dir']} | count={a['file_count']}\n")
                for fn in a["files"]:
                    f.write(f"    - {fn}\n")
        print(f"[WRITE] å¼‚å¸¸ä¼šè¯æ¸…å•ï¼š{anomaly_path}")
    else:
        print("âœ… æ²¡æœ‰å‘ç°å¼‚å¸¸ä¼šè¯ã€‚")

# ---------- ä¸»æµç¨‹ ----------
def main():
    selected_date = _resolve_date(IMPORT_DIR, DATE)
    print(f"[INFO ] Organizing exports for DATE={selected_date}")
    date_re = re.compile(rf"{selected_date}")

    if not IMPORT_DIR.exists():
        print(f"[ERROR] IMPORT_DIR ä¸å­˜åœ¨ï¼š{IMPORT_DIR}")
        sys.exit(1)
    OUTPUT_ROOT.mkdir(parents=True, exist_ok=True)
    day_root = OUTPUT_ROOT / selected_date
    day_root.mkdir(parents=True, exist_ok=True)

    # 1) æ‰¾åˆ°è¯¥æ—¥æœŸçš„ tar
    tars = sorted(IMPORT_DIR.glob(f"{selected_date}_*.tar"))
    if not tars:
        print(f"[WARN ] æœªåœ¨ {IMPORT_DIR} æ‰¾åˆ° {selected_date}_*.tar")
        # æ²¡ tar ä¹Ÿå…è®¸ç»§ç»­ï¼ˆæ¯”å¦‚ä½ æ‰‹åŠ¨æ”¾äº†ç›®å½•ï¼‰ï¼Œè¿™é‡Œåªæ˜¯æç¤º
    else:
        print("[INFO ] TAR files:")
        for t in tars:
            print("  -", t.name)

    total_moved = 0
    sessions_count = 0

    with tempfile.TemporaryDirectory(prefix=f"org_{selected_date}_") as tmpdir:
        tmp_root = pathlib.Path(tmpdir)

        # 2) è§£å‹
        extracted_dirs = []
        for t in tars:
            try:
                extracted_dirs.append(extract_tar(t, tmp_root))
            except Exception as e:
                print(f"[ERR  ] è§£å‹å¤±è´¥ {t.name}: {e}")

        # å¦‚æœæ²¡æœ‰ tarï¼Œä¹Ÿæ”¯æŒç›´æ¥åœ¨ IMPORT_DIR/selected_date å­ç›®å½•é‡ŒæŠ“
        if not extracted_dirs:
            if (IMPORT_DIR / selected_date).exists():
                extracted_dirs.append(IMPORT_DIR / selected_date)
            else:
                # æœ€åå…œåº•ï¼šæ•´ä¸ª IMPORT_DIR
                extracted_dirs.append(IMPORT_DIR)

        # 3) èšåˆï¼šä¸¥æ ¼ -> æ‰‹æœºtxt -> å®½æ¾
        groups = defaultdict(lambda: {"files": [], "times": []})
        residuals = []

        for d in extracted_dirs:
            for f in collect_files(d, date_re):
                name = f.name

                key, hms = parse_strict(name)
                if not key and name.lower().startswith("log_") and name.lower().endswith(".txt"):
                    key, hms = parse_phone_txt(name)
                if not key:
                    key, hms = parse_relax_any(name)

                if key:
                    groups[key]["files"].append(f)
                    if hms:
                        groups[key]["times"].append(hms)
                else:
                    residuals.append(f)

        # 4) è®¡ç®—ä»£è¡¨æ—¶é—´ï¼ˆminï¼‰
        session_rep_time_sec = {}
        for key, info in groups.items():
            rep_hms = min(info["times"]) if info["times"] else None
            session_rep_time_sec[key] = hhmmss_to_sec(rep_hms) if rep_hms else None

        # 5) å…œåº•ï¼ˆä»…æ—¥æœŸ+æ—¶é—´æ—¶ï¼ŒæŒ‰ä»£è¡¨æ—¶é—´â€œå°±è¿‘åˆå¹¶â€ï¼‰
        misc_dir = day_root / f"misc_{selected_date}"
        for f in residuals:
            date_only, hms = parse_date_time_only(f.name)
            if date_only == selected_date and hms:
                hms_sec = hhmmss_to_sec(hms)
                cand_key, cand_dist = None, None
                for k, sec in session_rep_time_sec.items():
                    if sec is None:
                        continue
                    dist = abs(sec - hms_sec)
                    if (cand_dist is None) or (dist < cand_dist):
                        cand_dist = dist
                        cand_key = k
                if cand_key and (cand_dist is not None) and (cand_dist <= MAX_ASSIGN_DELTA_SEC):
                    groups[cand_key]["files"].append(f)
                    continue
            # å®åœ¨æ— æ³•å½’å±ï¼Œæ”¾ misc
            misc_dir.mkdir(parents=True, exist_ok=True)
            target = misc_dir / f.name
            print(f"[MISC ] {f}  ->  {target}")
            safe_move(f, target)
            total_moved += 1

        # 6) è¾“å‡ºä¼šè¯ç›®å½•å¹¶ç§»åŠ¨
        for key in sorted(groups.keys()):
            times = groups[key]["times"]
            rep = min(times) if times else None
            folder_name = f"{key}_{rep}" if rep else key  # <CID>_<ACTION>_<DATE>_<HHMMSS>
            sess_dir = day_root / folder_name
            if not sess_dir.exists():
                sess_dir.mkdir(parents=True, exist_ok=True)
                sessions_count += 1

            print(f"\n[SESSION] {folder_name}  ->  {sess_dir}  (æ–‡ä»¶æ•° {len(groups[key]['files'])})")
            for f in groups[key]["files"]:
                target = sess_dir / f.name
                print(f"  [MOVE] {f}  ->  {target}")
                safe_move(f, target)
                total_moved += 1

    print(f"\n[DONE ] æ—¥æœŸ {selected_date}ï¼šä¼šè¯ {sessions_count} ä¸ªï¼Œç§»åŠ¨æ–‡ä»¶ {total_moved} ä¸ªã€‚")
    print(f"[PATH ] è¾“å‡ºç›®å½•ï¼š{day_root}")
    print(f"[NOTE ] æº tar ä»åœ¨ï¼š{IMPORT_DIR}ï¼ˆæœªæ”¹åŠ¨ï¼‰")

    # 7) ç»Ÿè®¡å¯¼å‡ºï¼ˆå½“å¤©ï¼‰
    _csv  = day_root / f"session_summary_{selected_date}.csv"
    _anom = day_root / f"session_anomalies_{selected_date}.txt"
    summarize_sessions(day_root, selected_date, _csv, _anom, expected_files_per_session=EXPECTED_FILES_PER_SESSION)

if __name__ == "__main__":
    main()
